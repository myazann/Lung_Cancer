{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1LUvt8Y0wZET4jLHjEnS_CPQHgtWrqnuf",
      "authorship_tag": "ABX9TyP0LaJMo1DfLmLjXl/gThWD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myazann/Lung_Cancer/blob/main/Data_Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrWhUm_56KSs"
      },
      "source": [
        "!git init\n",
        "!git pull https://github.com/myazann/TCIA-API-SDK.git\n",
        "\n",
        "!cp -r /content/tcia-rest-client-python/src/* /content\n",
        "\n",
        "!rm -rf tcia-rest-client-java/\n",
        "!rm -rf tcia-rest-client-python/\n",
        "\n",
        "!cp /content/drive/MyDrive/Annotation.zip /content\n",
        "!cp /content/drive/MyDrive/bboxs.json /content\n",
        "!cp /content/drive/MyDrive/images.zip /content\n",
        "!cp /content/drive/MyDrive/ptnt_to_series_ids.json /content\n",
        "!unzip Annotation.zip > /dev/null\n",
        "!rm Annotation.zip\n",
        "\n",
        "!pip install xmltodict\n",
        "!rm -rf sample_data\n",
        "!rm sample.py\n",
        "!rm README.md\n",
        "\n",
        "!pip install pip install pandasql\n",
        "from tciaclient import TCIAClient\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from xml.etree import cElementTree as ElementTree\n",
        "import xmltodict\n",
        "import urllib.request, urllib.error, urllib.parse\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import pandasql as ps\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tc = TCIAClient(baseUrl=\"https://services.cancerimagingarchive.net/services/v4\", resource = \"TCIA\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzeZLn7JTCc1"
      },
      "source": [
        "## Get bounding boxs associated with the images\n",
        "\n",
        "if os.path.exists(\"bboxs.json\"):\n",
        "  \n",
        "  with open(\"bboxs.json\") as file:\n",
        "    bboxs = json.load(file)\n",
        "\n",
        "else:\n",
        "\n",
        "  folders = np.array(os.listdir(\"Annotation\"))\n",
        "\n",
        "  bboxs = {}\n",
        "\n",
        "  for folder in folders:\n",
        "    path = \"Annotation/\" + folder\n",
        "    for img in os.listdir(path):\n",
        "      file_path = path + \"/\" + img\n",
        "      try:\n",
        "        dt = xmltodict.parse(ElementTree.tostring(ElementTree.parse(file_path).getroot()))[\"annotation\"][\"object\"]\n",
        "        if isinstance(dt, list):\n",
        "          box_list = []\n",
        "          for box in dt:\n",
        "            box_list.append(box)\n",
        "        else:\n",
        "          dt = dt[\"bndbox\"]\n",
        "        img_name = folder + \"-\" + img.split(\".x\")[0]\n",
        "        bboxs[img_name] = dt\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "  with open('bboxs.json', \"w\") as json_file:\n",
        "    json.dump(bboxs, json_file)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qktuafs7Ugb"
      },
      "source": [
        "##Get Annotations, Patients, Series ID's and SOP ID's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKSVcyP7bclK"
      },
      "source": [
        "## Get the series id of each patient with the most images\n",
        "\n",
        "if os.path.exists(\"ptnt_to_series_ids.json\"):\n",
        "  with open(\"ptnt_to_series_ids.json\") as file:\n",
        "    ptnt_to_series_ids = json.load(file)\n",
        "\n",
        "else:\n",
        "  clctn = \"Lung-PET-CT-Dx\"\n",
        "  series = json.loads(tc.get_series(collection = clctn, modality = \"CT\").read())\n",
        "  ptnt_to_series_ids = pd.DataFrame()\n",
        "\n",
        "  pt_id = []\n",
        "  series_id = []\n",
        "  img_count = []\n",
        "\n",
        "  for elem in series:\n",
        "    try:\n",
        "      if elem[\"BodyPartExamined\"] == \"CHEST\":\n",
        "        pt_id.append(elem[\"PatientID\"].split(\"-\")[1])\n",
        "        series_id.append(elem[\"SeriesInstanceUID\"])\n",
        "        img_count.append(elem[\"ImageCount\"])\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "  ptnt_to_series_ids[\"Patient_ID\"] = pt_id\n",
        "  ptnt_to_series_ids[\"Series_ID\"] = series_id\n",
        "  ptnt_to_series_ids[\"Image_Count\"] = img_count\n",
        "\n",
        "  ptnt_to_series_ids = ps.sqldf(\"\"\"SELECT Patient_ID,MAX(Image_Count) Image_Count ,\n",
        "  MAX(Series_ID) Series_ID FROM ptnt_to_series_ids\n",
        "  GROUP BY Patient_ID\"\"\")\n",
        "\n",
        "  ptnts_with_bboxs = [box.split(\"-\")[0] for box in bboxs.keys()]\n",
        "  ptnt_to_series_ids = ptnt_to_series_ids.loc[ptnt_to_series_ids[\"Patient_ID\"].isin(ptnts_with_bboxs)]\n",
        "\n",
        "  _, ptnt_to_series_ids = train_test_split(ptnt_to_series_ids, test_size = 0.25, random_state = 0)\n",
        "\n",
        "  ptnt_to_series_ids = dict((p,s) for p,s in ptnt_to_series_ids[[\"Patient_ID\",\"Series_ID\"]].values)\n",
        "\n",
        "  with open('ptnt_to_series_ids.json', 'w') as json_file:\n",
        "    json.dump(ptnt_to_series_ids, json_file)\n",
        "\n",
        "  !cp ptnt_to_series_ids.json /content/drive/MyDrive"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weSCHcGc7uSq"
      },
      "source": [
        "## Download images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_IeR-qPOxZj"
      },
      "source": [
        "counter = 0\n",
        "\n",
        "if not os.path.exists(\"images\"):\n",
        "  os.mkdir(\"images\")\n",
        "  ptnt_to_series_ids_nd = ptnt_to_series_ids\n",
        "else:\n",
        "  downloaded_patients = os.listdir(\"images\")\n",
        "  counter = len(downloaded_patients)\n",
        "  ptnt_to_series_ids_nd = dict((p,s) for p,s in ptnt_to_series_ids.items() if p not in downloaded_patients)\n",
        "\n",
        "\n",
        "for ptnt in ptnt_to_series_ids_nd:\n",
        "\n",
        "  print(ptnt)\n",
        "  ptnt_folder = \"images/\" + ptnt\n",
        "  os.mkdir(ptnt_folder)\n",
        "\n",
        "  tc.get_image(ptnt_to_series_ids_nd[ptnt], ptnt_folder, ptnt + \".zip\")\n",
        "\n",
        "  zip_folder = ptnt_folder + \"/\" + ptnt + \".zip\"\n",
        "  subprocess.check_call([\"unzip\", str(zip_folder), \"-d\", str(ptnt_folder)])\n",
        "  subprocess.call([\"rm\", zip_folder])\n",
        "\n",
        "  counter += 1\n",
        "\n",
        "  print(counter)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA78ZNWUWiET"
      },
      "source": [
        "## Split files into train and test (%80-%20). A patient who is in train cannot be in test and classes should be distributed equally in both sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugxWgSbPF9mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "631ff301-f9c8-4fb5-e9ef-d4410cdd6164"
      },
      "source": [
        "ptnt_classes = {}\n",
        "\n",
        "ptnt_classes[\"A\"] = [k for k in ptnt_to_series_ids.keys() if \"A\" in k]\n",
        "ptnt_classes[\"B\"] = [k for k in ptnt_to_series_ids.keys() if \"B\" in k]\n",
        "ptnt_classes[\"G\"] = [k for k in ptnt_to_series_ids.keys() if \"G\" in k]\n",
        "\n",
        "train_ptnts = []\n",
        "val_ptnts = []\n",
        "\n",
        "for cls in ptnt_classes.keys():\n",
        "  permutated_list = list(np.random.permutation(np.array(ptnt_classes[cls])))\n",
        "  val_len = int(len(permutated_list)*0.25)\n",
        "\n",
        "  val_ptnts.extend(permutated_list[0:val_len])\n",
        "  train_ptnts.extend(permutated_list[val_len:])\n",
        "  \n",
        "\n",
        "!mkdir /content/lung_ct_train\n",
        "!mkdir /content/lung_ct_val\n",
        "\n",
        "\n",
        "for ptnt in os.listdir(\"images\"):\n",
        "  cur_path = \"images/\" + ptnt\n",
        "  \n",
        "  if ptnt in train_ptnts:\n",
        "    os.mkdir(\"/content/lung_ct_train/\" + ptnt)\n",
        "    new_path = \"lung_ct_train/\" + ptnt\n",
        "  else:\n",
        "    os.mkdir(\"/content/lung_ct_val/\" + ptnt)\n",
        "    new_path = \"lung_ct_val/\" + ptnt\n",
        "  os.rename(cur_path, new_path)\n",
        "\n",
        "\n",
        "subprocess.call([\"zip\",\"-r\",\"lung_ct_train.zip\",\"lung_ct_train\",\">\", \"/dev/null\"])\n",
        "subprocess.call([\"mv\",\"lung_ct_train.zip\",\"./drive/MyDrive/\"])\n",
        "\n",
        "subprocess.call([\"zip\",\"-r\",\"lung_ct_val.zip\",\"lung_ct_val\",\">\", \"/dev/null\"])\n",
        "subprocess.call([\"mv\",\"lung_ct_val.zip\",\"./drive/MyDrive/\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCkrh_fq-SHh"
      },
      "source": [
        "## Get the image id's (SOP) in each series\n",
        "\n",
        "for ptnt, series in ptnt_to_series_ids.items():\n",
        "  sop_to_series_ids = {}\n",
        "  sop = json.loads(tc.get_SOP_instance(series).read())\n",
        "\n",
        "  sop_to_series_ids[series] = [s[\"SOPInstanceUID\"] for s in sop]\n",
        "  ptnt_to_series_ids[ptnt] = sop_to_series_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8eYQIy4QWxp"
      },
      "source": [
        "ptnts_with_bboxs = [box.split(\"-\")[0] for box in bboxs.keys()]\n",
        "imgs_with_bboxs = [box.split(\"-\")[1] for box in bboxs.keys()]\n",
        "\n",
        "ptnt_to_series_ids = dict((ptnt, ptnt_to_series_ids[ptnt]) for ptnt in ptnt_to_series_ids.keys() if ptnt in ptnts_with_bboxs)\n",
        "\n",
        "for ptnt in ptnt_to_series_ids:\n",
        "  series_id = list(ptnt_to_series_ids[ptnt].keys())[0]\n",
        "  for img in ptnt_to_series_ids[ptnt][series_id]:\n",
        "    if img not in imgs_with_bboxs:\n",
        "      ptnt_to_series_ids[ptnt][series_id].remove(img)\n",
        "\n",
        "with open('ptnt_to_series_ids.json', 'w') as json_file:\n",
        "  json.dump(ptnt_to_series_ids, json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zbdzImIdGOz"
      },
      "source": [
        "counter = 0\n",
        "\n",
        "if not os.path.exists(\"images\"):\n",
        "  os.mkdir(\"images\")\n",
        "else:\n",
        "  counter = len(os.listdir(\"images\"))\n",
        "  \n",
        "  for ptnt in os.listdir(\"images\"):\n",
        "    for img in os.listdir(\"images/\" + ptnt):\n",
        "      downloaded_images.append(img)\n",
        "  counter = len(downloaded_images)\n",
        "  downloaded_images = [img.split(\".d\")[0] for img in downloaded_images]\n",
        "\n",
        "\n",
        "for ptnt in ptnt_to_series_ids:\n",
        "\n",
        "  series_id = list(ptnt_to_series_ids[ptnt].keys())[0]\n",
        "  print(ptnt)\n",
        "\n",
        "  if not os.path.exists(\"./images/\" + ptnt):\n",
        "    os.mkdir(\"./images/\" + ptnt)\n",
        "\n",
        "    for img in ptnt_to_series_ids[ptnt][series_id]:\n",
        "      download_path = \"./images/\" + ptnt + \"/\" + img + \".dcm\"\n",
        "      tc.get_single_image(series_id, img, downloadPath = download_path)\n",
        "      counter += 1\n",
        "      print(counter)\n",
        "\n",
        "      if counter % 1000 == 0:\n",
        "        subprocess.call([\"zip\",\"-r\",\"images.zip\",\"images\",\">\", \"/dev/null\"])\n",
        "        subprocess.call([\"mv\",\"images.zip\",\"./drive/MyDrive/\"])   \n",
        "\n",
        "  else:\n",
        "\n",
        "    for img in ptnt_to_series_ids[ptnt][series_id]:\n",
        "\n",
        "      if img not in downloaded_images:\n",
        "        download_path = \"./images/\" + ptnt + \"/\" + img + \".dcm\"\n",
        "        tc.get_single_image(series_id, img, downloadPath = download_path)\n",
        "        counter += 1\n",
        "        print(counter)\n",
        "\n",
        "      if counter % 1000 == 0:\n",
        "        subprocess.call([\"zip\",\"-r\",\"images.zip\",\"images\",\">\", \"/dev/null\"])\n",
        "        subprocess.call([\"mv\",\"images.zip\",\"./drive/MyDrive/\"])      \n",
        "\n",
        "  print(counter)\n",
        "\n",
        "subprocess.call([\"zip\",\"-r\",\"images.zip\",\"images\",\">\", \"/dev/null\"])\n",
        "subprocess.call([\"mv\",\"images.zip\",\"./drive/MyDrive/\"])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}